{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a6nCmIz5B_L"
      },
      "source": [
        "# **Quantum-Classical Hybrid Model for Demand Forecasting**\n",
        "This is the first attempt to use **Quantum Computing** and Quantum machine learning models in demand forecasting\n",
        "\n",
        "## **Project Overview**\n",
        "\n",
        "This project introduces a **Quantum-Classical Hybrid Model** for demand forecasting, tailored specifically for an ice cream shop. This represents the **first ever** attempt to integrate a **Quantum Approximate Optimization Algorithm (QAOA)** with classical machine learning models to enhance demand forecasting accuracy. By combining the strengths of quantum computing with traditional models, this approach aims to achieve superior performance over purely classical techniques.\n",
        "\n",
        "### **Significance of Using QAOA for Demand Forecasting**\n",
        "\n",
        "**QAOA** is a quantum algorithm designed for solving combinatorial optimization problems, making it highly suitable for complex data patterns and non-linear relationships often found in demand forecasting. Its application in this project represents a pioneering effort to leverage quantum computing for predictive analytics in a practical business scenario.\n",
        "\n",
        "### **How QAOA Works**\n",
        "\n",
        "- **Quantum Circuit Design:** QAOA operates through a series of quantum gates arranged in layers, each layer consisting of parameterized gates that adjust the quantum state of qubits.\n",
        "  \n",
        "- **Entanglement and Superposition:** By using quantum phenomena such as superposition and entanglement, QAOA explores a vast number of potential solutions simultaneously, which classical algorithms cannot achieve as efficiently.\n",
        "\n",
        "- **Cost Function Optimization:** The algorithm iteratively adjusts gate parameters to minimize a cost function, typically representing the difference between predicted and actual outcomes. This process is akin to training in classical machine learning but utilizes the quantum state space for optimization.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Motivation and Benefits of Using Quantum Algorithms**\n",
        "\n",
        "- **Exploration of Quantum Computing in Real-World Applications:** Quantum algorithms like QAOA are poised to solve complex optimization problems faster than classical methods, especially as quantum hardware continues to improve.\n",
        "- **Enhanced Model Performance:** Quantum algorithms can explore larger and more complex state spaces, potentially finding better solutions for optimization problems like demand forecasting.\n",
        "- **Potential for Early Adoption Advantages:** As quantum computing matures, integrating quantum algorithms into business processes now can provide a strategic edge and prepare organizations for a quantum-enabled future.\n",
        "\n",
        "### **Why Use QAOA in Demand Forecasting?**\n",
        "\n",
        "1. **Optimization Capabilities:** QAOA is designed to solve combinatorial optimization problems, which are inherent in demand forecasting tasks where numerous factors (temperature, seasonality, promotions, etc.) must be considered simultaneously.\n",
        "2. **Handling Complex Relationships:** Quantum circuits can capture complex, non-linear relationships within data that might be challenging for classical models to represent effectively.\n",
        "3. **Scalability Potential:** As quantum hardware scales, the efficiency of quantum algorithms like QAOA could significantly outperform classical algorithms, providing faster and more accurate forecasts.\n",
        "\n",
        "### **Methodology**\n",
        "\n",
        "- **Quantum Model (QAOA):** Utilizes a 5-qubit QAOA circuit to process key features influencing ice cream sales, such as temperature, promotions, and customer sentiment.\n",
        "- **Classical Model:** Implements a Random Forest Regressor to leverage traditional machine learning strengths, processing additional features like seasonality and patterns.\n",
        "- **Hybrid Approach:** Combines predictions from both the quantum and classical models using a machine learning model (e.g., a linear regression or neural network) to optimally weight the contributions of each, delivering a refined final forecast.\n",
        "\n",
        "### **Key Components**\n",
        "\n",
        "\n",
        "1. **QAOA Training:** The quantum circuit is trained using Pennylane and Qiskit, optimizing parameters to minimize the prediction error using mean squared error as the cost function.\n",
        "2. **Classical Model Training:** A Random Forest Regressor is trained on complementary features to provide a baseline prediction.\n",
        "3. **Model Combination:** The outputs from both models are combined using an additional machine learning model to derive final sales predictions.\n",
        "\n",
        "\n",
        "### **Potential Impact and Future Directions**\n",
        "\n",
        "- **Enhanced Forecasting Accuracy:** Combining quantum and classical models aims to surpass traditional forecasting accuracy, reducing inventory costs and improving customer satisfaction.\n",
        "- **Scalability to Other Domains:** While focused on an ice cream shop, this hybrid model approach can be generalized to other sectors where demand forecasting is crucial, such as retail, logistics, and manufacturing.\n",
        "- **Foundation for Future Quantum Applications:** By pioneering the integration of QAOA into business analytics, this project lays the groundwork for future quantum-enhanced decision-making tools.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOpgZGLfw7yI",
        "outputId": "8324f6ee-25c1-4dca-c7fa-f310d860eee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.37.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.3)\n",
            "Collecting rustworkx (from pennylane)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting semantic-version>=2.7 (from pennylane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.6.12-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.37 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.37.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.7.4)\n",
            "Downloading PennyLane-0.37.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.6.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.37.0-cp310-cp310-manylinux_2_28_x86_64.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, semantic-version, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.6.12 pennylane-0.37.0 pennylane-lightning-0.37.0 rustworkx-0.15.1 semantic-version-2.10.0\n"
          ]
        }
      ],
      "source": [
        "pip install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pXpJHBkNw2i1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"ice_cream_sales_data.csv\")\n",
        "\n",
        "# Split into quantum and classical features\n",
        "quantum_features = [ \"Promotion\", \"Cost\", \"Customer Sentiment\",\"Temperature\",\"Day of Week\"]\n",
        "classical_features = [ \"Humidity\", \"Holiday\", \"Wind Speed\", \"Rainfall\"]\n",
        "\n",
        "# Extract features and target\n",
        "X_quantum = df[quantum_features].values\n",
        "X_classical = df[classical_features].values\n",
        "y = df[\"Sales\"].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3fz-4B65WDt"
      },
      "source": [
        "## **Part 2: Quantum Model with QAOA**\n",
        "\n",
        "### **Objective**\n",
        "\n",
        "- Implement a QAOA model using a 5-qubit quantum circuit.\n",
        "- Train the QAOA model on selected features where quantum computing could provide a distinct advantage, such as non-linear relationships and complex data patterns.\n",
        "\n",
        "### **Quantum Model (QAOA)**\n",
        "\n",
        "1. **Circuit Design:**\n",
        "   - **Qubits:** Utilizes 5 qubits corresponding to the features: Temperature, Day of the Week, Promotions, Cost, and Customer Sentiment.\n",
        "   - **QAOA Layers:** Consists of multiple layers with parameterized quantum gates, including RX and RZ rotations and entangling CNOT gates.\n",
        "\n",
        "2. **Training:**\n",
        "   - **Objective:** Minimize prediction error using Mean Squared Error as the cost function.\n",
        "   - **Optimization:** Parameters of the QAOA circuit were optimized using gradient descent techniques to align the circuit's output with actual sales data.\n",
        "\n",
        "3. **Evaluation:**\n",
        "   - Performance compared to classical models on similar features, demonstrating potential improvements in capturing complex patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cBzSjyYO5hiv"
      },
      "outputs": [],
      "source": [
        "# Number of qubits for quantum model\n",
        "n_qubits = 5\n",
        "\n",
        "# Create a device with n_qubits qubits\n",
        "dev = qml.device('default.qubit', wires=n_qubits)\n",
        "\n",
        "# Define the QAOA layer\n",
        "def qaoa_layer(gamma, beta):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(gamma[i], wires=i)\n",
        "    for i in range(n_qubits):\n",
        "        qml.RZ(beta[i], wires=i)\n",
        "    # Entanglement\n",
        "    for i in range(n_qubits - 1):\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "    qml.CNOT(wires=[n_qubits - 1, 0])  # Loop back\n",
        "\n",
        "# Define the QAOA circuit\n",
        "def qaoa_circuit(params, x=None):\n",
        "    # Data embedding\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(np.pi * x[i], wires=i)\n",
        "\n",
        "    # Apply QAOA layers\n",
        "    for i in range(n_layers):\n",
        "        qaoa_layer(params[2*i], params[2*i+1])\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Set the number of QAOA layers\n",
        "n_layers = 4\n",
        "\n",
        "# QNode\n",
        "qnode = qml.QNode(qaoa_circuit, dev)\n",
        "\n",
        "# Cost function: Mean Squared Error between prediction and target\n",
        "def cost(params, X, y):\n",
        "    predictions = [qnode(params, x=x) for x in X]  # Use only quantum features\n",
        "    predictions = np.array(predictions)\n",
        "    return np.mean((predictions - y) ** 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0VBzMQA5iBN"
      },
      "source": [
        "## **Part 3: Hybrid Model and Final Integration**\n",
        "\n",
        "### **Objective**\n",
        "\n",
        "- Combine the outputs of the classical and quantum models to form a unified hybrid prediction.\n",
        "- Use a meta-model (e.g., Linear Regression or Neural Network) to determine the optimal weightings between the quantum and classical outputs for final demand forecasting.\n",
        "\n",
        "### **Hybrid Model Integration**\n",
        "\n",
        "1. **Meta-Model Design:**\n",
        "   - A simple neural network or linear regression model takes predictions from both the QAOA and Random Forest models as inputs.\n",
        "   - **Output:** The meta-model produces the final forecast by learning the optimal blend of quantum and classical predictions.\n",
        "\n",
        "2. **Training and Evaluation:**\n",
        "   - Trained on a validation set to ensure generalization and avoid overfitting.\n",
        "   - Performance compared against individual models to assess the improvement from the hybrid approach.\n",
        "\n",
        "3. **Final Forecast:**\n",
        "   - The hybrid model's final predictions are validated against real sales data to ensure accuracy and reliability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pPHmFBYfw6aS"
      },
      "outputs": [],
      "source": [
        "# Part 3: Classical Model and Combining with QAOA\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train classical model (Random Forest) on classical features\n",
        "X_train_classical, X_test_classical, y_train, y_test = train_test_split(X_classical, y, test_size=0.2, random_state=42)\n",
        "classical_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "classical_model.fit(X_train_classical, y_train)\n",
        "\n",
        "# Predictions from the classical model\n",
        "classical_predictions = classical_model.predict(X_test_classical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vk6LKkw_jID",
        "outputId": "4367099e-29c5-49c8-e1ed-519ffaeae38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 10: Cost = 0.1127909865198242\n",
            "Step 20: Cost = 0.08661005436377836\n",
            "Step 30: Cost = 0.06823360637821003\n",
            "Step 40: Cost = 0.04015791000782772\n",
            "Step 50: Cost = 0.02886810917126309\n",
            "Step 60: Cost = 0.026277606241288755\n",
            "Step 70: Cost = 0.02511876462361054\n",
            "Step 80: Cost = 0.024064996986326526\n",
            "Step 90: Cost = 0.023764469951423242\n",
            "Step 100: Cost = 0.02364701137349949\n"
          ]
        }
      ],
      "source": [
        "# Train QAOA model on quantum features\n",
        "X_train_quantum, X_test_quantum = train_test_split(X_quantum, test_size=0.2, random_state=42)\n",
        "init_params = 0.01 * np.random.randn(2 * n_layers, n_qubits)\n",
        "opt = qml.AdamOptimizer(stepsize=0.4)\n",
        "\n",
        "# Training loop for QAOA model\n",
        "params = init_params\n",
        "for i in range(100):\n",
        "    params = opt.step(lambda p: cost(p, X_train_quantum, y_train), params)\n",
        "    if (i + 1) % 10 == 0:\n",
        "        current_cost = cost(params, X_train_quantum, y_train)\n",
        "        print(f\"Step {i+1}: Cost = {current_cost}\")\n",
        "\n",
        "# Predictions from the QAOA model\n",
        "quantum_predictions = np.array([qnode(params, x=x) for x in X_test_quantum])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIQZtN5A_jy0",
        "outputId": "e0cf2c37-826c-4690-811e-e39bb9447095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Mean Squared Error: 0.0730966389810125\n"
          ]
        }
      ],
      "source": [
        "# Combine predictions using a neural network to find optimal weights\n",
        "combined_features = np.vstack((classical_predictions, quantum_predictions)).T\n",
        "combining_model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=500, random_state=42)\n",
        "combining_model.fit(combined_features, y_test)\n",
        "\n",
        "# Final predictions\n",
        "final_predictions = combining_model.predict(combined_features)\n",
        "mse = mean_squared_error(y_test, final_predictions)\n",
        "print(f\"Final Mean Squared Error: {mse}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
